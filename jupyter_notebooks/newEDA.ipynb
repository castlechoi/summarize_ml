{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fiwK03v1P3tJ"
      ],
      "authorship_tag": "ABX9TyPxArlFO29TjRdnLmMURxwC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###pre"
      ],
      "metadata": {
        "id": "fiwK03v1P3tJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQWtFd32OLUA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier,RandomForestClassifier\n",
        "from sklearn.linear_model import Lasso,Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./train.csv')\n",
        "test_df = pd.read_csv('./test.csv')"
      ],
      "metadata": {
        "id": "sPTuTNhnOseO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_df.drop(columns = ['TIMESTAMP','PRODUCT_ID', 'Y_Quality','Y_Class'])\n",
        "train_y = train_df[['Y_Quality','LINE']]\n",
        "test_x = test_df.drop(columns = ['TIMESTAMP','PRODUCT_ID'])"
      ],
      "metadata": {
        "id": "GA8er46iO1oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_lst = ['A_31','T_31','O_31']\n",
        "line_lst = ['T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305']"
      ],
      "metadata": {
        "id": "9LmUA9Eu1g0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['LINE'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AHf13X89xAj",
        "outputId": "9e358086-dbc5-4eae-e375-a18999dae2c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    if i == 'LINE':\n",
        "      print(le.transform(line_lst))\n",
        "    \n",
        "    for label in np.unique(test_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6fDHBnoXf3U",
        "outputId": "614e1b5c-750c-47ef-8a67-4d95a6e9fd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 4 5 1 0]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_a = train_x[train_x['LINE'] == 2]\n",
        "train_b = train_x[train_x['LINE'] == 3]\n",
        "train_c = train_x[train_x['LINE'] == 4]\n",
        "train_d = train_x[train_x['LINE'] == 5]\n",
        "train_e = train_x[train_x['LINE'] == 1]\n",
        "train_f = train_x[train_x['LINE'] == 0]\n",
        "\n",
        "\n",
        "train_a_y = train_y[train_y['LINE'] == line_lst[0]]\n",
        "train_b_y = train_y[train_y['LINE'] == line_lst[1]]\n",
        "train_c_y = train_y[train_y['LINE'] == line_lst[2]]\n",
        "train_d_y = train_y[train_y['LINE'] == line_lst[3]]\n",
        "train_e_y = train_y[train_y['LINE'] == line_lst[4]]\n",
        "train_f_y = train_y[train_y['LINE'] == line_lst[5]]\n",
        "train_a_y = train_a_y['Y_Quality']\n",
        "train_b_y = train_b_y['Y_Quality']\n",
        "train_c_y = train_c_y['Y_Quality']\n",
        "train_d_y = train_d_y['Y_Quality']\n",
        "train_e_y = train_e_y['Y_Quality']\n",
        "train_f_y = train_f_y['Y_Quality']\n",
        "\n",
        "test_a = test_x[test_x['LINE'] == 2]\n",
        "test_b = test_x[test_x['LINE'] == 3]\n",
        "test_c = test_x[test_x['LINE'] == 4]\n",
        "test_d = test_x[test_x['LINE'] == 5]\n",
        "test_e = test_x[test_x['LINE'] == 1]\n",
        "test_f = test_x[test_x['LINE'] == 0]\n",
        "\n",
        "col = train_x.columns\n",
        "na_a_col = []\n",
        "na_b_col = []\n",
        "na_c_col = []\n",
        "na_d_col = []\n",
        "na_e_col = []\n",
        "na_f_col = []\n",
        "for i in col:\n",
        "  if train_a[i].count() == 0:\n",
        "    na_a_col.append(i)\n",
        "  if train_b[i].count() == 0:\n",
        "    na_b_col.append(i)\n",
        "  if train_c[i].count() == 0:\n",
        "    na_c_col.append(i)\n",
        "  if train_d[i].count() == 0:\n",
        "    na_d_col.append(i)\n",
        "  if train_e[i].count() == 0:\n",
        "    na_e_col.append(i)\n",
        "  if train_f[i].count() == 0:\n",
        "    na_f_col.append(i)\n",
        "\n",
        "train_a = train_a.drop(na_a_col, axis = 1)\n",
        "train_b = train_b.drop(na_b_col, axis = 1)\n",
        "train_c = train_c.drop(na_c_col, axis = 1)\n",
        "train_d = train_d.drop(na_d_col, axis = 1)\n",
        "train_e = train_e.drop(na_e_col, axis = 1)\n",
        "train_f = train_f.drop(na_f_col, axis = 1)\n",
        "\n",
        "test_a = test_a.drop(na_a_col, axis = 1)\n",
        "test_b = test_b.drop(na_b_col, axis = 1)\n",
        "test_c = test_c.drop(na_c_col, axis = 1)\n",
        "test_d = test_d.drop(na_d_col, axis = 1)\n",
        "test_e = test_e.drop(na_e_col, axis = 1)\n",
        "test_f = test_f.drop(na_f_col, axis = 1)\n",
        "print(f\"Shape of each Line : \\n{train_a.shape}  \\n{train_b.shape} \\n{train_c.shape}\\\n",
        " \\n{train_d.shape} \\n{train_e.shape} \\n{train_f.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sao3uefPIaG",
        "outputId": "a5e9aa2a-52a9-43e7-dfa5-408081c3fec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of each Line : \n",
            "(78, 1970)  \n",
            "(42, 1977) \n",
            "(175, 673) \n",
            "(174, 673) \n",
            "(70, 888) \n",
            "(59, 888)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_a = train_a.fillna(0)\n",
        "train_b = train_b.fillna(0)\n",
        "train_c = train_c.fillna(0)\n",
        "train_d = train_d.fillna(0)\n",
        "train_e = train_e.fillna(0)\n",
        "train_f = train_f.fillna(0)\n",
        "\n",
        "test_a = test_a.fillna(0)\n",
        "test_b = test_b.fillna(0)\n",
        "test_c = test_c.fillna(0)\n",
        "test_d = test_d.fillna(0)\n",
        "test_e = test_e.fillna(0)\n",
        "test_f = test_f.fillna(0)"
      ],
      "metadata": {
        "id": "BkCCcKGDUc28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 라인별로 특성값이 하나 밖에 없는 값 제거\n",
        "train_total = [train_a, train_b, train_c, train_d, train_e, train_f]\n",
        "test_total = [test_a,test_b,test_c,test_d,test_e,test_f]\n",
        "for idx, t_df in enumerate(train_total):\n",
        "  tmp = []\n",
        "  for i in t_df:\n",
        "    if i == 'LINE' or i == 'PRODUCT_CODE':\n",
        "      continue\n",
        "    if len(t_df[i].unique()) < 2:\n",
        "      tmp.append(i)\n",
        "  t_df.drop(tmp, axis = 1, inplace = True)\n",
        "  test_total[idx].drop(tmp, axis = 1, inplace = True)\n",
        "  print(f\" {t_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JoSgZL4Myh",
        "outputId": "22d68e52-bc80-4fa8-a35e-6fed51c258e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (78, 1722)\n",
            " (42, 1726)\n",
            " (175, 571)\n",
            " (174, 543)\n",
            " (70, 733)\n",
            " (59, 732)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라쏘"
      ],
      "metadata": {
        "id": "uF4Icf-8U50A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF_a = RandomForestRegressor(max_depth = 10, min_samples_leaf = 2,\\\n",
        "          min_samples_split = 10,n_estimators = 10, n_jobs = -1).fit(train_a, train_a_y)\n",
        "RF_b = RandomForestRegressor(max_depth = 40, min_samples_leaf = 4,\\\n",
        "          min_samples_split = 10,n_estimators = 20, n_jobs = -1).fit(train_b, train_b_y)\n",
        "RF_c = RandomForestRegressor(max_depth = 20, min_samples_leaf = 10,\\\n",
        "          min_samples_split = 50,n_estimators = 20, n_jobs = -1).fit(train_c, train_c_y)\n",
        "RF_d = RandomForestRegressor(max_depth = 20, min_samples_leaf = 2,\\\n",
        "          min_samples_split = 20,n_estimators = 20, n_jobs = -1).fit(train_d, train_d_y)\n",
        "RF_e = RandomForestRegressor(max_depth = 30, min_samples_leaf = 4,\\\n",
        "          min_samples_split = 10,n_estimators = 10, n_jobs = -1).fit(train_e, train_e_y)\n",
        "RF_f = RandomForestRegressor(max_depth = 12, min_samples_leaf = 2,\\\n",
        "          min_samples_split = 20,n_estimators = 30, n_jobs = -1).fit(train_f, train_f_y)"
      ],
      "metadata": {
        "id": "D0g-4zJ550AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# params = { 'n_estimators' : [10,100,500,1000,2000],\n",
        "#            'max_depth' : [ 10, 12,14,16],\n",
        "#            'min_samples_leaf' : [8,10,12,14],\n",
        "#            'min_samples_split' : [8,12, 16, 20]\n",
        "#             }\n",
        "# grid_cv = GridSearchCV(RF_a, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_a, train_a_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
        "\n",
        "# grid_cv = GridSearchCV(RF_b, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_b, train_b_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
        "\n",
        "# grid_cv = GridSearchCV(RF_c, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_c, train_c_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
        "\n",
        "# grid_cv = GridSearchCV(RF_d, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_d, train_d_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
        "\n",
        "# grid_cv = GridSearchCV(RF_e, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_e, train_e_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
        "\n",
        "# grid_cv = GridSearchCV(RF_f, param_grid = params, cv = 3, n_jobs = -1)\n",
        "# grid_cv.fit(train_f, train_f_y)\n",
        "# print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
        "# print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "id": "PytLQXuBW7os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_a = RF_a.predict(test_a)\n",
        "pred_b = RF_b.predict(test_b)\n",
        "pred_c = RF_c.predict(test_c)\n",
        "pred_d = RF_d.predict(test_d)\n",
        "pred_e = RF_e.predict(test_e)\n",
        "pred_f = RF_f.predict(test_f)"
      ],
      "metadata": {
        "id": "DMiDhHVIXomH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###pre"
      ],
      "metadata": {
        "id": "NNhoBUGo-ogI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_df.drop(columns = ['TIMESTAMP','PRODUCT_ID','Y_Class'])\n",
        "train_y = train_df[['Y_Class','LINE']]\n",
        "test_x = test_df.drop(columns = ['TIMESTAMP','PRODUCT_ID'])"
      ],
      "metadata": {
        "id": "GCFxeQ5S-ogR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    if i == 'LINE':\n",
        "      print(le.transform(line_lst))\n",
        "    \n",
        "    for label in np.unique(test_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244eaecf-a8bd-4ccf-c67b-dd3999620df7",
        "id": "NmHNEZtf-ogR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 4 5 1 0]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_a = train_x[train_x['LINE'] == 2]\n",
        "train_b = train_x[train_x['LINE'] == 3]\n",
        "train_c = train_x[train_x['LINE'] == 4]\n",
        "train_d = train_x[train_x['LINE'] == 5]\n",
        "train_e = train_x[train_x['LINE'] == 1]\n",
        "train_f = train_x[train_x['LINE'] == 0]\n",
        "\n",
        "\n",
        "train_a_y = train_y[train_y['LINE'] == line_lst[0]]\n",
        "train_b_y = train_y[train_y['LINE'] == line_lst[1]]\n",
        "train_c_y = train_y[train_y['LINE'] == line_lst[2]]\n",
        "train_d_y = train_y[train_y['LINE'] == line_lst[3]]\n",
        "train_e_y = train_y[train_y['LINE'] == line_lst[4]]\n",
        "train_f_y = train_y[train_y['LINE'] == line_lst[5]]\n",
        "train_a_y = train_a_y['Y_Class']\n",
        "train_b_y = train_b_y['Y_Class']\n",
        "train_c_y = train_c_y['Y_Class']\n",
        "train_d_y = train_d_y['Y_Class']\n",
        "train_e_y = train_e_y['Y_Class']\n",
        "train_f_y = train_f_y['Y_Class']\n",
        "\n",
        "test_a = test_x[test_x['LINE'] == 2]\n",
        "test_b = test_x[test_x['LINE'] == 3]\n",
        "test_c = test_x[test_x['LINE'] == 4]\n",
        "test_d = test_x[test_x['LINE'] == 5]\n",
        "test_e = test_x[test_x['LINE'] == 1]\n",
        "test_f = test_x[test_x['LINE'] == 0]\n",
        "\n",
        "# col = train_x.columns\n",
        "# na_a_col = []\n",
        "# na_b_col = []\n",
        "# na_c_col = []\n",
        "# na_d_col = []\n",
        "# na_e_col = []\n",
        "# na_f_col = []\n",
        "# for i in col:\n",
        "#   if train_a[i].count() == 0:\n",
        "#     na_a_col.append(i)\n",
        "#   if train_b[i].count() == 0:\n",
        "#     na_b_col.append(i)\n",
        "#   if train_c[i].count() == 0:\n",
        "#     na_c_col.append(i)\n",
        "#   if train_d[i].count() == 0:\n",
        "#     na_d_col.append(i)\n",
        "#   if train_e[i].count() == 0:\n",
        "#     na_e_col.append(i)\n",
        "#   if train_f[i].count() == 0:\n",
        "#     na_f_col.append(i)\n",
        "\n",
        "# train_a = train_a.drop(na_a_col, axis = 1)\n",
        "# train_b = train_b.drop(na_b_col, axis = 1)\n",
        "# train_c = train_c.drop(na_c_col, axis = 1)\n",
        "# train_d = train_d.drop(na_d_col, axis = 1)\n",
        "# train_e = train_e.drop(na_e_col, axis = 1)\n",
        "# train_f = train_f.drop(na_f_col, axis = 1)\n",
        "\n",
        "# test_a = test_a.drop(na_a_col, axis = 1)\n",
        "# test_b = test_b.drop(na_b_col, axis = 1)\n",
        "# test_c = test_c.drop(na_c_col, axis = 1)\n",
        "# test_d = test_d.drop(na_d_col, axis = 1)\n",
        "# test_e = test_e.drop(na_e_col, axis = 1)\n",
        "# test_f = test_f.drop(na_f_col, axis = 1)"
      ],
      "metadata": {
        "id": "mRea524D-ogS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_a = train_a.fillna(0)\n",
        "train_b = train_b.fillna(0)\n",
        "train_c = train_c.fillna(0)\n",
        "train_d = train_d.fillna(0)\n",
        "train_e = train_e.fillna(0)\n",
        "train_f = train_f.fillna(0)\n",
        "\n",
        "test_a = test_a.fillna(0)\n",
        "test_b = test_b.fillna(0)\n",
        "test_c = test_c.fillna(0)\n",
        "test_d = test_d.fillna(0)\n",
        "test_e = test_e.fillna(0)\n",
        "test_f = test_f.fillna(0)"
      ],
      "metadata": {
        "id": "P_iL57NA-ogS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 라인별로 특성값이 하나 밖에 없는 값 제거\n",
        "train_total = [train_a, train_b, train_c, train_d, train_e, train_f]\n",
        "test_total = [test_a, test_b,test_c,test_d,test_e,test_f]\n",
        "for idx, t_df in enumerate(train_total):\n",
        "  tmp = []\n",
        "  for i in t_df:\n",
        "    if i == 'LINE' or i == 'PRODUCT_CODE':\n",
        "      continue\n",
        "    if len(t_df[i].unique()) < 2:\n",
        "      tmp.append(i)\n",
        "  t_df.drop(tmp, axis = 1, inplace = True)\n",
        "  test_total[idx].drop(tmp, axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "g7UG3fUf-ogS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_a['Y_Quality'] = pred_a\n",
        "test_b['Y_Quality'] = pred_b\n",
        "test_c['Y_Quality'] = pred_c\n",
        "test_d['Y_Quality'] = pred_d\n",
        "test_e['Y_Quality'] = pred_e\n",
        "test_f['Y_Quality'] = pred_f"
      ],
      "metadata": {
        "id": "-v8esOf6-_dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cola = ['Y_Quality'] + test_a.columns.to_list()[:-1]\n",
        "new_colb = ['Y_Quality'] + test_b.columns.to_list()[:-1]\n",
        "new_colc = ['Y_Quality'] + test_c.columns.to_list()[:-1]\n",
        "new_cold = ['Y_Quality'] + test_d.columns.to_list()[:-1]\n",
        "new_cole = ['Y_Quality'] + test_e.columns.to_list()[:-1]\n",
        "new_colf = ['Y_Quality'] + test_f.columns.to_list()[:-1]\n",
        "test_a = test_a[new_cola]\n",
        "test_b = test_b[new_colb]\n",
        "test_c = test_c[new_colc]\n",
        "test_d = test_d[new_cold]\n",
        "test_e = test_e[new_cole]\n",
        "test_f = test_f[new_colf]"
      ],
      "metadata": {
        "id": "-fg9K5yHF8L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# train_total = [train_a, train_b, train_c, train_d, train_e, train_f]\n",
        "# test_total = [test_a, test_b,test_c,test_d,test_e,test_f]\n",
        "# for k in range(len(train_total)):\n",
        "#   print(test_total[k].shape)\n",
        "#   for i in train_total[k].columns:\n",
        "#     mm = MinMaxScaler()\n",
        "#     fitted = mm.fit(train_total[k][i].values.reshape(-1,1))\n",
        "#     output = mm.transform(train_total[k][i].values.reshape(-1,1))\n",
        "#     out_test = mm.transform(test_total[k][i].values.reshape(-1,1))\n",
        "#     test_total[k][i] = out_test.reshape(-1)\n",
        "#     train_total[k][i] = output.reshape(-1)\n",
        "#   print(test_total[k].shape)"
      ],
      "metadata": {
        "id": "h_TPSlGtWKcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#    train"
      ],
      "metadata": {
        "id": "kQX5_9jQsDVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z232TDYd-zZw",
        "outputId": "cc88ba13-6e11-444f-88d8-6f01d1698f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.22.4)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.7.3)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.8/dist-packages (from pytorch-tabnet) (4.64.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.5.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 트리 기반\n",
        "from sklearn.model_selection import KFold\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "\n",
        "def Objective(trial):\n",
        "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
        "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
        "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
        "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
        "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
        "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
        "    \n",
        "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
        "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
        "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
        "                     mask_type=mask_type, n_shared=n_shared,\n",
        "                     scheduler_params=dict(mode=\"min\",\n",
        "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10), # changing sheduler patience to be lower than early stopping patience \n",
        "                                           min_lr=1e-5,\n",
        "                                           factor=0.5,),\n",
        "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                     verbose=True\n",
        "                     ) #early stopping\n",
        "    #valid\n",
        "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    CV_score_array    =[]\n",
        "\n",
        "    for train_index, test_index in kf.split(train_a):\n",
        "        X_train, X_valid = train_a[train_index], train_a[test_index]\n",
        "        y_train, y_valid = train_a_y[train_index], train_a_y[test_index]\n",
        "        clf = TabNetClassifier(**tabnet_params)\n",
        "        clf.fit(X_train=X_train, y_train=y_train,\n",
        "                  eval_set=[(X_valid, y_valid)],\n",
        "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
        "                  eval_metric=['accuracy'])\n",
        "        CV_score_array.append(clf.best_cost)\n",
        "    avg = np.mean(CV_score_array)\n",
        "    return avg\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\", study_name='TabNet optimization')\n",
        "study.optimize(Objective, timeout=6*60) #5 hours\n",
        "\n",
        "TabNet_params = study.best_params\n",
        "print(TabNet_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "CrxrvOAAsLVr",
        "outputId": "e08ce5ea-7c43-4de4-d60f-e3f4ae488301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3f812a4e810a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                      optimizer_params=dict(lr=0.001 ),mask_type=\"entmax\")\n\u001b[1;32m     21\u001b[0m   \u001b[0mgrid_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f1_macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   grid_cv.fit(train_total[i].to_numpy(),\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mtrain_y_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  print(y_preds[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXPPRUQnp5qi",
        "outputId": "bae51034-cd62-414c-e978-5ba0b995d003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 2 1 0 0 0 2 2 0 2]\n",
            "[0 1 0 0 2 2 2 2 2 2 2 2 2 2 1 2 2 0 2 1 2 2 2 2 1 1]\n",
            "[1 1 1 2 2 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 0 2 2 2 2 2 1 1 1 2 2 1 1 1 1 1 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 2 2 2 2]\n",
            "[1 1 1 2 0 1 1 1 2 2 0 2 1 1 1 1 1 2 2 2 2 2 0 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 2 2 2 0 2 2 0 2 1 2 2 2 2 2 2 2 2 2 0 1 2 0 2 0 0 0 0 2 0\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2]\n",
            "[1 1 1 1 0 2 2 1 2 0 2 2 0 0]\n",
            "[0 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    \n",
        "    for label in np.unique(test_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "print('Done.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHXZJ4i1EGYY",
        "outputId": "f0de8170-427f-42d5-e8b3-64227e938e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  y_preds[i] = y_preds[i]"
      ],
      "metadata": {
        "id": "shqayDnU4bW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "f0aef4e4-d989-4e26-fcf1-e1369ff4f43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-d1d88769ee89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = []\n",
        "cnt = [0 for i in range(6)]\n",
        "test_prd = test_x['LINE']\n",
        "for idx,i in enumerate(test_prd):\n",
        "  if i == 2:\n",
        "    test_pred.append(y_preds[0][cnt[0]])\n",
        "    cnt[0] += 1\n",
        "  elif i == 3:\n",
        "    test_pred.append(y_preds[1][cnt[1]])\n",
        "    cnt[1] += 1\n",
        "  elif i == 4:\n",
        "    test_pred.append(y_preds[2][cnt[2]])\n",
        "    cnt[2] += 1\n",
        "  elif i == 5:\n",
        "    test_pred.append(y_preds[3][cnt[3]])\n",
        "    cnt[3] += 1\n",
        "  elif i == 1:\n",
        "    test_pred.append(y_preds[4][cnt[4]])\n",
        "    cnt[4] += 1\n",
        "  else:\n",
        "    test_pred.append(y_preds[5][cnt[5]])\n",
        "    cnt[5] += 1"
      ],
      "metadata": {
        "id": "O1YdJuDK_eh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_pred)):\n",
        "  print(test_pred[i])"
      ],
      "metadata": {
        "id": "O4tIJTjbFixX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d207ae-e1db-4c41-b319-47ece093372e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#save"
      ],
      "metadata": {
        "id": "NuD8ODK9Yl3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['Y_Class'] = test_pred\n",
        "path = 'baselinne.csv'\n",
        "submit.to_csv(path, index = False)"
      ],
      "metadata": {
        "id": "xa3zmTaPAIRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "1d6fd6dc-6bde-4f33-ba2c-4f6d42029ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32mnewEDA.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_Class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'baselinne.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m             \u001b[0msparsify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparsify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m             \u001b[0mindex_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m             \u001b[0mescape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mString\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimplementing\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0mobject\u001b[0m \u001b[0mimplementing\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mCompressionOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mFilePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePath' from 'pandas._typing' (/usr/local/lib/python3.8/dist-packages/pandas/_typing.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3cglpN5Qvz",
        "outputId": "272346ae-ed27-4d91-9eb7-2e94936a21f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n"
          ]
        }
      ]
    }
  ]
}