{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castlechoi/summarize_ml/blob/main/NLP/Word2Vec_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "-BBDyvlo64jq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-_ioJx6Iequ"
      },
      "source": [
        "## Download corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siYoaOebIarP",
        "outputId": "b7c2a722-7ab0-4cf9-eb13-a6ba3078a0f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"book\", quiet = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsZGjVpZLHfR",
        "outputId": "45d940a9-d607-4592-87a8-e2e2fabcc650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# nltk.book에 저장된 다양한 corpus\n",
        "from nltk.book import *\n",
        "nltk.book.texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zp4hBDdLRo4"
      },
      "outputs": [],
      "source": [
        "# tokenize 모두 완료 되어 있음\n",
        "ex_book = nltk.book.text1[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_PuXfZtJv5Z"
      },
      "source": [
        "## Stop-words 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjDC1GjqJ33J",
        "outputId": "718ae467-7a80-45e4-cdd4-904653a864ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop-words의 개수 : 198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# stop-words에 특수기호 추가\n",
        "stopwords  = stopwords + ['.',',','\\'','!','?','\\\"','[',']','(',')','*','I',':',';','-','.\"','--','<','>']\n",
        "\n",
        "print(f'Stop-words의 개수 : {len(stopwords)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9_pdV7KQ3aa",
        "outputId": "76495347-e774-40c2-a962-b4ed847a3e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제외한 후 문장의 길이 : 2520\n"
          ]
        }
      ],
      "source": [
        "# 불용어 빠진 것을 확인\n",
        "ex_book_no_stopwords = [[t] for t in ex_book if t not in stopwords]\n",
        "print(f'불용어 제외한 후 문장의 길이 : {len(ex_book_no_stopwords)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing hyperparameter\n"
      ],
      "metadata": {
        "id": "MPW87KAt40kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_count = 2\n",
        "window = 2"
      ],
      "metadata": {
        "id": "yLBYPK0I43Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tBgafmjJp_a"
      },
      "source": [
        "## One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mTUkbRqJr9B"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri8z-PZIDGYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4df61f-4335-484a-d81d-f411a5198dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token의 개수 : [['S'], ['whale'], ['THE'], ['OF'], ['The'], ['WHALE'], ['A'], ['sea'], ['whales'], ['AND'], ['great'], ['Whale'], ['And'], ['Leviathan'], ['saw'], ['...'], ['one'], ['take'], ['There'], ['TO'], ['head'], ['ocean'], ['IN'], ['In'], ['It'], ['every'], ['water'], ['ship'], ['Sub'], ['Whales'], ['To'], ['BY'], ['would'], ['NANTUCKET'], ['near'], ['VOYAGE'], ['upon'], ['like'], ['He'], ['!\"'], ['animal'], ['shall'], ['?\"'], ['see'], ['mouth'], [',\"'], ['ON'], ['killed'], ['vast'], ['Sperm'], ['world'], ['D'], ['us'], ['sir'], ['ye'], ['HISTORY'], ['shore'], ['find'], ['So'], ['ever'], ['many'], ['NUEE'], ['open'], ['said'], ['They'], ['king'], ['NARRATIVE'], ['boats'], ['If'], ['HIS'], ['air'], ['This'], ['oil'], ['time'], ['little'], ['years'], ['known'], ['fish'], ['called'], ['God'], ['WHALING'], ['two'], ['GLOBE'], ['jaws'], ['boat'], ['seen'], ['never'], ['long'], ['blows'], ['mast'], ['seas'], ['first'], ['told'], ['whether'], ['FOR'], ['could'], ['Right'], ['vessel'], ['deep'], ['swallow'], ['hearts'], ['among'], ['FROM'], ['),'], ['large'], ['length'], ['may'], ['much'], ['land'], ['stone'], ['strong'], ['monsters'], ['even'], ['go'], ['beast'], ['order'], ['--\"'], ['SHIP'], ['say'], ['also'], ['monster'], ['bones'], ['view'], ['well'], ['OR'], ['came'], ['earth'], ['We'], ['T'], ['miles'], ['heart'], ['IBID'], ['form'], ['DICTIONARY'], ['quantity'], ['whenever'], ['either'], ['tail'], ['Which'], ['sail'], ['might'], ['high'], ['THOMAS'], ['maketh'], ['nothing'], ['While'], ['poor'], ['Ay'], ['VOYAGES'], ['E'], ['feet'], ['SIR'], ['way'], ['old'], ['without'], ['wide'], ['gulf'], ['look'], ['CETI'], ['frequently'], ['HOLLAND'], ['Indian'], ['Sea'], ['SPERMA'], ['BROWNE'], ['fishes'], ['floating'], ['Steady'], ['four'], ['ball'], ['come'], ['around'], ['besides'], ['side'], ['BENNETT'], ['works'], ['living'], ['EX'], ['Now'], ['Lord'], ['less'], ['promontory'], ['ago'], ['man'], ['ships'], ['made'], ['play'], ['breath'], ['PSALMS'], ['mighty'], ['answered'], ['sword'], ['serpent'], ['swimming'], ['bold'], ['close'], ['ROUND'], ['meet'], ['thing'], ['within'], ['behind'], ['huge'], ['swiftness'], ['monstrous'], ['days'], ['swallowed'], ['SPERM'], ['kind'], ['HENRY'], ['engaged'], ['LIFE'], ['KING'], ['OCEAN'], ['CRUISE'], ['things'], ['set'], ['wind'], ['coast'], ['sleeps'], ['art'], ['probably'], ['N'], ['striking'], ['caught'], ['VERSION'], ['National'], ['fly'], ['let'], ['noble'], ['U'], ['interest'], ['Some'], ['1828'], ['six'], ['men'], ['board'], ['WILLIAM'], ['haunts'], ['fable'], ['towards'], ['Call'], ['QUEEN'], ['waves'], ['Mr'], ['matter'], ['sporting'], ['wounded'], ['Like'], ['nature'], ['yards'], ['country'], ['English'], ['COMSTOCK'], ['Nantucket'], ['nearly'], ['HARRIS'], ['brought'], ['COLL'], ['stand'], ['forty'], ['eight'], ['fifty'], ['One'], ['blood'], ['swim'], ['whose'], ['Stern'], ['generally'], ['crews'], ['till'], ['almost'], ['Io'], ['dread'], ['attack'], ['thought'], ['sing'], ['sung'], ['larger'], ['people'], ['Not'], ['prevent'], ['CHAPTER'], ['SHIPWRECK'], ['hand'], ['ashore'], ['tribe'], ['round'], ['found'], ['passage'], ['sometimes'], ['sit'], ['nations'], ['London'], ['pipe'], ['As'], ['Dan'], ['year'], ['requires'], ['mariner'], ['FRENCH'], ['BURKE'], ['EDMUND'], ['PEKEE'], ['EXTRACTS'], ['mere'], ['.)'], ['devil'], ['appears'], ['gone'], ['street'], ['consideration'], ['right'], ['extracts'], ['SONG'], ['though'], ['Spermacetti'], ['immediately'], ['WEBSTER'], ['thrown'], ['HVALT'], ['must'], ['get'], ['least'], ['free'], ['jaw'], ['With'], ['grow'], ['FISHERY'], ['compare'], ['strike'], ['GOLDSMITH'], ['immense'], ['grammars'], ['pains'], ['brain'], ['body'], ['children'], ['velocity'], ['pale'], ['fail'], ['Usher'], ['main'], ['ACCOUNT'], ['royal'], ['armed'], ['seven'], ['Supplied'], ['Here'], ['ribs'], ['fire'], ['tears'], ['TALES'], ['make'], ['glasses'], ['created'], ['altogether'], ['important'], ['persons']]\n"
          ]
        }
      ],
      "source": [
        "# 토큰 집합 추출 ( 등장횟수가 2이하면 토큰화 안함)\n",
        "cut_off = 0\n",
        "\n",
        "tokens = pd.Series(ex_book_no_stopwords).value_counts()\n",
        "for i in range(len(tokens)):\n",
        "  if tokens[i] == min_count-1:\n",
        "    cut_off = i\n",
        "    break\n",
        "tokens = tokens[:cut_off].index.tolist()\n",
        "print(f'Token의 개수 : {tokens}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1jElU3oGhyk"
      },
      "outputs": [],
      "source": [
        "# token에 없는 데이터 모두 <unk>로 변경\n",
        "ex_book_process = [t if t in tokens else ['<unk>'] for t in ex_book_no_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygUi_7NUSAgy",
        "outputId": "90b856e5-0a08-4bbb-dc83-534c3e4ba685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서의 단의 개수 : 2520\n",
            "One-Hot vector의 크기 : 359\n"
          ]
        }
      ],
      "source": [
        "# One-Hot Encoding\n",
        "oe = OneHotEncoder()\n",
        "document_matrix = oe.fit_transform(ex_book_process)\n",
        "print(f'문서의 단의 개수 : {document_matrix.shape[0]}')\n",
        "print(f'One-Hot vector의 크기 : {document_matrix.shape[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2TBvGyeZByC"
      },
      "source": [
        "## GPU 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-08pgoQjYqb",
        "outputId": "7f596e39-bab6-4f78-c833-fff344bb435b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "#GPU 체크\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU is availalbe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Low-level"
      ],
      "metadata": {
        "id": "J9VnyFe37EY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train data preprocessing "
      ],
      "metadata": {
        "id": "ri8rts2u4ntK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM4OYUVSex_q"
      },
      "outputs": [],
      "source": [
        "# train_x에 CBOW의 input으로 들어가는 4개의 벡터\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(document_matrix.shape[0] - (window * 2)):\n",
        "  neighbor = []\n",
        "  neighbor.append(document_matrix[i].toarray())\n",
        "  neighbor.append(document_matrix[i+1].toarray())\n",
        "  neighbor.append(document_matrix[i+3].toarray())\n",
        "  neighbor.append(document_matrix[i+4].toarray())\n",
        "\n",
        "  train_x.append(neighbor)\n",
        "  train_y.append(document_matrix[i+2].toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alsm-k18kTIQ",
        "outputId": "f2e471e7-186b-4664-a205-699ea7b30cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x의 shape : torch.Size([2516, 4, 359])\n",
            "train_y의 shape : torch.Size([2516, 359])\n"
          ]
        }
      ],
      "source": [
        "train_x_tensor = torch.FloatTensor(train_x).view(-1,4,document_matrix.shape[1]).to(device)\n",
        "train_y_tensor = torch.FloatTensor(train_y).view(-1,document_matrix.shape[1]).to(device)\n",
        "\n",
        "print(f'train_x의 shape : {train_x_tensor.shape}') # 단어 개수 * 4 * one_hot\n",
        "print(f'train_y의 shape : {train_y_tensor.shape}') # 단어 개수 * one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2SSwhP2T7D_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "d005sfmT4ezD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 20000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "FaHcjOM05PfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAAl1iC9zk58"
      },
      "outputs": [],
      "source": [
        "# Define weights without bias\n",
        "W = torch.randn(document_matrix.shape[1],emb_vector_size).to(device).requires_grad_()\n",
        "W_prime = torch.randn(emb_vector_size,document_matrix.shape[1]).to(device).requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iitfzjLKUavm"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss\n",
        "CBOW_optimizer = optim.Adam([W], lr = lr)\n",
        "CBOW_optimizer_p = optim.Adam([W_prime], lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "1gATZ5t96fFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dThZmveFflDf",
        "outputId": "d3c3d9f0-9853-4da9-b491-7e57039c9104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 : 6.470300197601318\n",
            "epoch 500 : 5.733725547790527\n",
            "epoch 1000 : 5.087561130523682\n",
            "epoch 1500 : 4.510709762573242\n",
            "epoch 2000 : 4.055849552154541\n",
            "epoch 2500 : 3.769590377807617\n",
            "epoch 3000 : 3.6288301944732666\n",
            "epoch 3500 : 3.5637311935424805\n",
            "epoch 4000 : 3.5267300605773926\n",
            "epoch 4500 : 3.498671770095825\n",
            "epoch 5000 : 3.473546028137207\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = train_x_tensor @ W\n",
        "  y_pred = torch.mean(y_pred, dim = 1)\n",
        "  \n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = y_pred @ W_prime\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_optimizer.zero_grad()\n",
        "  CBOW_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_optimizer.step()\n",
        "  CBOW_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear2 = nn.Linear(document_matrix.shape[1], 10, bias = False).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(linear2.parameters(), lr = 0.03)\n",
        "# linear = nn.Linear(10,document_matrix.shape[1], bias = False).to(device)\n",
        "# optimizer_li = optim.Adam(linear.parameters(), lr = 0.03)"
      ],
      "metadata": {
        "id": "eRJ8Ojhb5o55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BKCQjaIam_",
        "outputId": "e922016b-b738-4724-d36f-e02595e56ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-13.9413, -52.3662, -13.6099,  ..., -18.9126,   5.3579,  -7.0772],\n",
            "        [ 10.6471,  -6.2604,  26.2865,  ...,  11.2689,  16.2586,   3.5958],\n",
            "        [-26.5287,   1.1138, -11.1199,  ..., -12.2975,  14.4212,  20.5384],\n",
            "        ...,\n",
            "        [ -9.3449,   8.7183,  25.1193,  ...,  13.9652,   2.6227, -46.6823],\n",
            "        [ 28.1785,  37.6067, -31.2626,  ..., -58.6981, -26.0484,  -0.5406],\n",
            "        [ 19.5140,   8.3228, -61.3487,  ...,   3.3553,   4.0766, -12.7914]],\n",
            "       device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for model in linear2.parameters():\n",
        "  print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW Using nn.Linear"
      ],
      "metadata": {
        "id": "yiMxNHhnlpsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "JbO4NMr_l3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 20000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "sYtNugRTlvve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, optimizer and loss\n",
        "CBOW_linear = nn.Linear(document_matrix.shape[1], emb_vector_size, bias = False).to(device)\n",
        "CBOW_linear_p = nn.Linear(emb_vector_size,document_matrix.shape[1], bias = False).to(device)\n",
        "\n",
        "CBOW_linear_optimizer = optim.Adam(CBOW_linear.parameters(), lr = lr)\n",
        "CBOW_linear_optimizer = optim.Adam(CBOW_linear_p.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sycbLupbl7rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "Ehj9RcufmTdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # Input : 4 neighbor vector\n",
        "  y_pred = CBOW_linear(train_x_tensor)\n",
        "  y_pred = torch.mean(y_pred, dim = 0)\n",
        "  \n",
        "  # Input : Embedding vector\n",
        "  # Output : predict one-hot vector\n",
        "  y_pred = CBOW_linear_p(y_pred)\n",
        "  y_pred = y_pred.softmax(dim = 1)\n",
        "  \n",
        "\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_optimizer.zero_grad()\n",
        "  CBOW_optimizer_p.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_optimizer.step()\n",
        "  CBOW_optimizer_p.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "id": "cxtqiW5UmS5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW using nn.Embedding"
      ],
      "metadata": {
        "id": "-n1NkZkZp4rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecCBOW(nn.Module):\n",
        "  def __init__(self, one_hot_dim, embedding_dim):\n",
        "    self.emb = nn.Embedding(num_embeddings = one_hot_dim, \n",
        "                              embedding_dim = embedding_dim)\n",
        "    \n",
        "    self.linear = nn.Linear(embedding_dim, one_hot_dim)\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "  def forward(self, x, tokens):\n",
        "    lookuptable = torch.mean(self.emb(x),dim = 1)\n",
        "    out = self.linear(lookuptable)\n",
        "    out = self.softmax(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "ho5q2O5pp79d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 20000\n",
        "lr = 0.001\n",
        "emb_vector_size = 2"
      ],
      "metadata": {
        "id": "GxG1aRRPuTkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model, optimizer and loss\n",
        "model = Word2VecCBOW(train_x_tensor.size(2),2)\n",
        "\n",
        "CBOW_emb_optimizer = optim.Adam(CBOW_linear.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "87-fRfmvuU4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs+1):\n",
        "  # CBOW model\n",
        "  y_pred = model(train_x_tensor)\n",
        "\n",
        "  # compute loss\n",
        "  loss = criterion(y_pred , train_y_tensor)\n",
        "  \n",
        "  # initiate optimizer\n",
        "  CBOW_emb_optimizer.zero_grad()\n",
        "  # backpropagation\n",
        "  loss.backward()\n",
        "  CBOW_emb_optimizer.step()\n",
        "\n",
        "  if i % 500 == 0:\n",
        "    print(f'epoch {i} : {loss.item()}')"
      ],
      "metadata": {
        "id": "Eb3uica1uV84"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-BBDyvlo64jq",
        "r-_ioJx6Iequ",
        "W_PuXfZtJv5Z",
        "MPW87KAt40kZ",
        "3tBgafmjJp_a",
        "N2TBvGyeZByC",
        "J9VnyFe37EY5"
      ],
      "authorship_tag": "ABX9TyNumJn0BO3IDqAgk6YkxjqW",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}